<!DOCTYPE html>
<html>
    <head>
  	<script src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js"></script>
		<script src="/js/jquery.collapse.js"></script>

		<script type="text/javascript" src="/js/shCore.js"></script>
		<script type="text/javascript" src="/js/shBrushPython.js"></script>
		<script type="text/javascript" src="/js/shBrushSql.js"></script>
		<script type="text/javascript" src="/js/shBrushPlain.js"></script>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>

    <title>Generating Custom Music Recommendation Systems</title>
    <link rel="icon" type="image/png" href="/img/profile.png">
    <link rel="stylesheet" href="../style.css">
    <link href="/css/shCore.css" rel="stylesheet" type="text/css" />
		<link href="/css/shThemeDefault.css" rel="stylesheet" type="text/css" />
		<link rel="stylesheet" href="/css/font-awesome/css/font-awesome.min.css">
    <link href="//fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="//fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

		<link rel="favicon-144-precomposed"  href="/img/profile.png">
		<link rel="shortcut icon" href="/img/profile.png">

    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

    <script type="text/javascript" src="//use.typekit.net/sjt4iho.js"></script>
 		<script type="text/javascript">try{Typekit.load();}catch(e){}</script>

      	<script src="../node_modules/chart.js/dist/Chart.js"></script>
		<script src="../js/jquery-1.11.0.js"></script>


    <style>
    /***** BASE STYLES *****/

    code {
        color: inherit;
        background-color: rgba(0, 0, 0, 0.04);
      }
 pre:not([class]) {
    background-color: white;
  }

    .fa {
      cursor: pointer;
    }

    nav ul li a {
      font-family: Lato, proxima-nova,proxima-nova,'proxima nova','helvetica neue',helvetica,sans-serif;
      color: #E8E8E8;
      text-decoration: none;
      transition: color 0.1s;
      letter-spacing: 1px;
    }

    nav ul li a:hover {
      color: #B82601;
    }
     #bootstrap-overrides  .nav-toggle.show {
        height: 50px;
        transform: translateY(0%);
        transition: transform 0.9s ease;
      }

     #bootstrap-overrides  .main-navigation {
        position: fixed;
        top: 0;
        left:0;
        width: 270px;
        height: 100%;
        background: rgba(29, 55, 69, 0.9);
      }

    .center {
      max-width: 1170px;
      margin: 0 auto;
      position: relative;
    }
    .img-center{
      margin-left: 115px;
      margin-top: 40px;
      margin-bottom: 40px;
    }

    .wrapper {
      margin-left: 230px;
    }

    /** Exeptions **/
    article#one {
        margin-bottom: 50px;
        padding: 0;
    }

    article#two {
        padding-top: 0
    }

    article#four h2 {
        margin-top:.5em;
    }

    article#eight .quote {
        margin-top: 30px 0 75px 0;
    }

    article#eight .center .left, article#six .center .left {
        margin-right: 5%;
    }

    article#eight .right, article#six .right {
        width: 45%;
    }

    article#eight .right img, article#six .right img {
        width: 100%;
    }

    /*** Footer ***/
      footer {
        background-color: #1D3745;
        width: 100%;
        position: absolute;
        z-index: 9999;
        bottom: -70px;
      }

       footer p {
        float: left;
      }

      .mktoForm {
        width: auto!important;
      }


      /***** Desktop Small *****/
      @media screen and (max-width: 1441px) {
        .center {
            max-width: 970px;
        }
        .container .sideText1, .container .sideText2, .container .sideText3, .container .sideText4, .container .sideText5 {
          margin-left: 60px;
          margin-right: auto;
        }

        .container .sideText1 p,
.container .sideText2 p, .container .sideText3 p, .container .sideText4
p, .container .sideText5 p {
          margin-left: 0;
        }
      }
      @media screen and (max-width: 1225px) {
        .center {
          max-width: 870px;
        }
      }
      @media screen and (max-width: 1170px) {
        .center {
          max-width: 770px;
        }
        footer {
          display: none;
        }
      }
      @media screen and (max-width: 1024px) {
        .center {
          max-width: 670px;
        }
      }
    </style>


<style>.mktoGen.mktoImg {display:inline-block; line-height:0;}</style>
</head>
<body id="bootstrap-overrides">
<style type="text/css">
#bootstrap-overrides hr.star-light {
border-color: #000000;
margin-left: auto;
margin-right: auto;}

#bootstrap-overrides div.post-overlay-header{
display:inline-block;
margin-left:30px;
margin-right:auto;
width:350px;
height:312px;

}
canvas {
padding-left: 0;
padding-right: 0;
margin-left: auto;
margin-right: auto;
display: block;
width: 90px;
}
</style>
  	</body>
	<body class="layout" id="bodyId">

		<div class="extraWrapper" style="position:relative;">
			<!-- DESKTOP FIXED NAV -->
         	<div id="desktopNav">
            <div style="position: relative; height: 100%;">
               <nav>
                  <ul class="firstUL">
                    <br>
                    <li class="navSection"><span class="navHeadline"><a style="color: #B82601;" href="/">Home</a></span>
                      <ul class="secondUL">
                          <li><a href="/#portfolio">Portfolio</a></li>
                          <li><a href="/blog/">Blog</a></li>
                      </ul>
                    </li>
                    <li class="navSection"><span class="navHeadline">Contents</span>
                      <ul class="secondUL">
                          <li><a href="/examples/SmoothPageScroll/#one">Goal</a></li>
                          <li><a href="/examples/SmoothPageScroll/#two">Approach</a></li>
                          <li><a href="/examples/SmoothPageScroll/#three">Exploratory Data Analysis</a></li>
                          <li><a href="/examples/SmoothPageScroll/#four">Methods To Recommend Songs</a></li>
                          <li><a href="/examples/SmoothPageScroll/#five">Results</a></li>
                          <li><a href="/examples/SmoothPageScroll/#six">Recommending Songs Based on Metadata</a></li>
                          <!--<li><a href="/examples/SmoothPageScroll/#seven">Emailing Results and Scheduling the Model</a></li>-->
                          <li><a href="/examples/SmoothPageScroll/#eight">Conclusion</a></li>
                          <li><a href="/examples/SmoothPageScroll/#forecast">Related Projects</a></li>
                      </ul>
                    </li>

                  </ul>
              </nav>
            </div>
          	</div>
	<div class="wrapper" id="header">
<p><br></p>
<h1 align="center" style = "margin: 0;">Generating Custom Music Recommendation Systems</h1>
<header>
    <hr class="star-light">
</header>
</div>
          	<div class="wrapper">
				<!-- Resolution 1 -->
				<article id="one">
      				<div class="center">
              			<div>
              				<h2>Goal</h2>
                      <p>The goal is to build a music recommendation system that can provide custom playlists for individual users based on collaborative and metadata filtering. Currently music service providers have generic (and popular), mood-based playlists, that are the same for all users. Here, I suggest improvements to these playlists by offering custom options for each user based on song metadata.</p>
                      <p>The complete code can be found on github <a target='_blank' href="https://github.com/moocarme/Music-Recommendation-System">here</a>.</p>
              			</div>
              			<div class="left"></div>
      				</div>
    			</article>
    			<!-- End Resolution 1 -->

				<!-- Resolution 2 -->
				<article id="two">

         	 			<div class="center">
            				<h2>Approach</h2>
								<p>I will first determine the the best method to recommend songs to users based on the most listened songs, song-song similarity, and user-user similarity. This will form the basis of the playlist creator. The specific playlist will then be constructed from these songs, since the ultimate goal is to create a playlist of songs the user likes. The songs will be chosen based on the type of playlist, i.e., workout, chillout, discover new artists, etc, and the songs are chosen based on their metadata.</p>
                <p>The data comes from the <a target='_blank' href="http://labrosa.ee.columbia.edu/millionsong/pages/getting-dataset">Million Song Dataset</a> which has metadata on 1 million songs. The metadata comes from the <a target='_blank' target='_blank' href="http://the.echonest.com/">The Echo Nest</a>, that is know taken over by <a target='_blank' href="https://developer.spotify.com/spotify-echo-nest-api/">Spotify</a> earlier in 2016. The dataset of users listener histories comes from <a target='_blank' href="https://www.kaggle.com/c/msdchallenge">kaggle</a> that had a competition on the subject a few years ago. The listening history was kept hidden by kaggle, so half the total data was not available to me, however this can be supplemented by the million song dataset that can be found on the <a target='_blank' href="https://archive.ics.uci.edu/ml/datasets/YearPredictionMSD">UCI Machine Learning Repository</a>. However for a single machine the kaggle dataset with 110000 unique users and 149029 unique songs is enough to test hypotheses.</p>
            				<div class="left">
              					<div class="container">
                					<div class="sideText2">
                  						<span class="line"></span>
                  						<p></p>
                					</div>
              					</div>

            				</div>
         				</div>

      			</article>
      			<!-- End Resolution 2 -->

	  			<!-- Resolution 3 -->
	  			<article id="three" style="background-color:#f7f7f7;">
          			<div class="center">
          				<p><br></p>
        				<h2>Exploratory Data Analysis</h2>
              				<p><br></p>
                      <p>Exploratory data analysis is performed in R to get a general feel for the data.</p>
                      <div data-collapse>
                        <h4> See here &#9660;</h4>
                           <div>
                             <pre class= "brush: python"># Load in libraries
library(readr)
library(dplyr)
library(tidyr)
library(RSQLite)
library(ggplot2)

# Load in data and create data frames
# User data
user_data <- as.data.frame(read.table('data/kaggle/kaggle_users.txt'))
colnames(user_data) <- c('User_ID')
user_data <- mutate(user_data, UID = row(user_data))

# Songs data
song_data <- as.data.frame(read.table('data/kaggle/kaggle_songs.txt'))
colnames(song_data) <- c('Song_ID', 'index')

# triplets in the form (User_ID, Song_ID, number of plays)
triplets <- as.data.frame(read_table('data/kaggle/kaggle_visible_evaluation_triplets.txt'))
colnames(triplets) <- c('User_ID', 'Song_ID', 'Plays')

# dataframe to convert song ID to track ID since metadata is from different source
song2track <- as.data.frame(read.table('data/kaggle/taste_profile_song_to_tracks.txt', fill= TRUE))
colnames(song2track) <- c('Song_ID', 'Track_ID')

# Join dataframe
totdf <- left_join(triplets, song2track, by = "Song_ID")

# Load data from databases using SQLite
con = dbConnect(drv=RSQLite::SQLite(), dbname="data/MillionSongSubset/AdditionalFiles/track_metadata.db")
songs <- dbGetQuery(con, 'SELECT * FROM songs')

con_meta = dbConnect(drv=RSQLite::SQLite(), dbname="song_metadata.sqlite")
song_metadata <- dbGetQuery(con_meta, 'SELECT track_id, loudness, time_signature, song_hotttnesss FROM song_metadata')

con_simArt = dbConnect(drv=RSQLite::SQLite(), dbname="data/MillionSongSubset/AdditionalFiles/artist_similarity.db")
sim_Artists <- dbGetQuery(con_simArt, 'SELECT * FROM songs')

# Join all data sources and remove unnecessary columns
totdf2 <- totdf %>% left_join(songs, by = c('Track_ID' = 'track_id')) %>%
  filter(!is.na(title)) %>%
  left_join(song_metadata, by = c('Track_ID' = 'track_id')) %>%
  select(-song_id, -track_7digitalid, -shs_perf, -shs_work)

# Exploratory data analysis
popular_songs <- totdf2 %>%
  dplyr::group_by(title, artist_name) %>%
  dplyr::summarise(Total.plays = sum(Plays)) %>%
  dplyr::arrange(desc(Total.plays)) %>%
  dplyr::top_n(100)

popular_artists <- totdf2 %>%
  dplyr::group_by(artist_name) %>%
  dplyr::summarise(Total.plays = sum(Plays)) %>%
  dplyr::arrange(desc(Total.plays)) %>%
  dplyr::top_n(100)

hottest_artists<- totdf2 %>%
  dplyr::select(artist_name, artist_hotttnesss) %>%
  dplyr::distinct() %>%
  dplyr::arrange(desc(artist_hotttnesss)) %>%
  dplyr::top_n(100)

hottest_songs <- totdf2 %>%
  dplyr::select(artist_name, title, song_hotttnesss) %>%
  dplyr::distinct() %>%
  dplyr::arrange(desc(song_hotttnesss)) %>%
  dplyr::top_n(100)

songs_per_user <- totdf2 %>%
  dplyr::select(User_ID, Song_ID) %>%
  dplyr::group_by(User_ID) %>%
  dplyr::summarize(Total.Songs = n()) %>%
  dplyr::arrange(Total.Songs) %>%
  dplyr::group_by(Total.Songs) %>%
  dplyr::summarise(Total.Count = n()) %>%
  dplyr::mutate(Cum.Sum = cumsum(Total.Count))

ggplot() + geom_line(data = songs_per_user, aes(x = Total.Songs, y = Cum.Sum/max(Cum.Sum)))

users_per_song <- totdf2 %>%
  dplyr::select(User_ID, Song_ID) %>%
  dplyr::group_by(Song_ID) %>%
  dplyr::summarise(Total.Users = n()) %>%
  dplyr::group_by(Total.Users) %>%
  dplyr::summarise(Total.Count = n()) %>%
  dplyr::mutate(Cum.Sum = cumsum(Total.Count))

ggplot() +
  geom_line(data = users_per_song, aes(x = Total.Users, y = Cum.Sum/max(Cum.Sum))) +
  scale_x_log10()

ggplot() + geom_histogram(data = filter(totdf2, year>1900), aes(x = year), binwidth = 1,
                          fill = '#18BC9C', color = '#2C3E50') +  xlim(1940,2012) +
  labs(title = 'Number of Songs per Year', x = 'Year', y = 'Count')+
  theme(plot.title = element_text(size=22), axis.text.x = element_text(size=18),
        axis.text.y = element_text(size=18), text = element_text(size = 20))

ggplot(data = filter(totdf2, year>1900),
       aes(x = as.factor(year), y = loudness) ) + geom_boxplot(aes(fill = (year))) +
  scale_fill_gradient(low = 'yellow', high = 'red') +
  scale_x_discrete(breaks = seq(1920, 2010, 10)) +
  labs(title = 'Loudness vs Year', x = 'Year', y = 'Loudness (dB)')+
  theme(plot.title = element_text(size=22), axis.text.x = element_text(size=18),
        axis.text.y = element_text(size=18), text = element_text(size = 20))

                             </pre>
                            </div>

                      </div>
<h4>Most Popular Songs</h4>
<p>Popular songs based on total numer of plays across all users.</p>
<p><br></p>
 <table style="width:70%" align = "center">
  <tr>
    <th>Artist Name</th>
    <th>Song Title</th>
    <th>Total Plays</th>
  </tr>
  <tr>
    <td>Dwight Yoakam</td>
    <td>You're The One</td>
    <td>35432 </td>
  </tr>
  <tr>
    <td>Björk</td>
    <td>Undo</td>
    <td>33179</td>
  </tr>
  <tr>
    <td>Kings Of Leon</td>
    <td>Revelry</td>
    <td>24359</td>
  </tr>
  <tr>
    <td>Barry Tuckwell/Academy of St Martin-in-the-Fields/Sir Neville Marriner</td>
    <td>Horn Concerto No. 4 in E flat K495: II. Romance (Andante cantabile)</td>
    <td>17115</td>
  </tr>
  <tr>
    <td>Florence + The Machine</td>
    <td>Dog Days Are Over (Radio Edit)</td>
    <td>14279</td>
  </tr>
  <tr>
    <td>OneRepublic</td>
    <td>Secrets</td>
    <td>12392</td>
  </tr>
  <tr>
    <td>Sam Cooke</td>
    <td>Ain't Misbehavin</td>
    <td>11610</td>
  </tr>
  <tr>
    <td>Tub Ring</td>
    <td>Invalid</td>
    <td>10794 </td>
  </tr>
  <tr>
    <td>Lonnie Gordon</td>
    <td>Catch You Baby (Steve Pitron & Max Sanna Radio Edit)</td>
    <td>10515</td>
  </tr>
  <tr>
    <td>Five Iron Frenzy</td>
    <td>Canada</td>
    <td>9921</td>
  </tr>
</table>
<p><br></p>
<h4>Hotttest Songs</h4>
<p>Song hotttnesss[sic] is a metric defined by how much buzz the song is getting right now. This is derived from many sources, including mentions on the web, mentions in music blogs, music reviews, play counts, etc. </p>
<p><br></p>
 <table style="width:70%" align="center">
  <tr>
    <th>Artist Name</th>
    <th>Song Title</th>
    <th>Hotttnesss Value</th>
  </tr>
  <tr>
    <td>Florence + The Machine</td>
    <td>Dog Days Are Over (Radio Edit)</td>
    <td>1 </td>
  </tr>
  <tr>
    <td>OneRepublic</td>
    <td>Secrets</td>
    <td>1</td>
  </tr>
  <tr>
    <td>Pearl Jam</td>
    <td>Black</td>
    <td>1</td>
  </tr>
  <tr>
    <td>Modest Mouse</td>
    <td>Float On</td>
    <td>1</td>
  </tr>
  <tr>
    <td>Kings Of Leon</td>
    <td>Use Somebody</td>
    <td>1</td>
  </tr>
  <tr>
    <td>Jimmy Eat World</td>
    <td>The Middle</td>
    <td>1</td>
  </tr>
  <tr>
    <td>B.o.B</td>
    <td>Nothin' On You [feat. Bruno Mars] (Album Version)</td>
    <td>1</td>
  </tr>
  <tr>
    <td>MIKA</td>
    <td>Grace Kelly</td>
    <td>1</td>
  </tr>
  <tr>
    <td>Vampire Weekend</td>
    <td>Cape Cod Kwassa Kwassa (Album)</td>
    <td>1</td>
  </tr>
  <tr>
    <td>Train</td>
    <td>Marry Me</td>
    <td>1</td>
  </tr>
</table>
</p>
<p><br></p>
<p> Interestingly, despite song hotttness being defned from the amount of buzz the song is currently getting, we see songs that are relatively old, such as Pearl Jam's 'Black', and Jimmy Eat World's 'The Middle', that are from 1991 and 2001 respectively.</p>
<p><br></p>
<p><b>Total songs in the dataset versus the year they were released.</b></p>
<center><img class="img-responsive" src="figs/songs_per_year.png"  width="700" align="center"></center>
<p><br></p>
<p><b>Cumulative distribution function showing total number of songs have listened by less than x users.</b> For example, cumulative sum for 10 total users is around 137,000, this means that 137,000 songs have been listened to by at most 10 unique users.</p>
<center><img class="img-responsive" src="figs/users_per_song.png"  width="700" align="center"></center>
<p><br></p>
<p><b>Cumulative distribution function of the total number of users have listened to less than x total songs.</b> For example, the cumulative sum for 20 total songs is around 90,000, which means that 90,000 users have listened to at most 20 unique songs.</p>
<center><img class="img-responsive" src="figs/songs_per_user.png"   width="700" align="center"></center>
<p><br></p>
<p><b>Loudness versus year.</b> Although we acknowledge that comparing features over time may not help in recommending songs, it may be valuable for visualizing trends in data and discovering any possible insights. One relationship we see confirms the <a target='_blank' href="http://www.npr.org/2009/12/31/122114058/the-loudness-wars-why-music-sounds-worse">"loudness wars"</a>, that refers to the trend of increasing the audio levels of music. The concept derives from the principle that if the audio levels are higher than other songs, when played on the radio the song will be louder, and listeners may pay attention to the song more. This is captured below in the boxplot graph. </p>
<center><img class="img-responsive" src="figs/loudness_per_year.png"   width="900" align="center"></center>
<p><br></p>

            			<div class="left">
          				</div>
       				</div>
      			</article>
     			<!-- End Resolution 3 -->

    			<!-- Resolution 4 -->
    			<article id="four">
    				<div style="position: relative;">
      					<div class="center">

							<h2>Methods to Recommend Songs</h2>
							<p><br></p>
							<h3>Cosine Similarity</h3>
<p>When dealing with a large number of users and a large number of songs and find similarities between users or songs things can quickly get out of hand. For example, to calculate the song similarity between all songs we could go through each song and calculate its similarity with each other song, however that would involve nested for loops with <span class = "math">\(\frac{n(n-1)}{2} \)</span> operations. Since there are 149029 unique songs in the data set, this equates to 11104746906 operations. While this is highly parallelizable, for optimal use of resources, <b>we use linear algebra</b>.</p>
<p> To solve the similarity between users and songs we construct a sparse matrix, <span class = "math">\(R(i,j)\)</span>, that is <span class = "math">\(m\times n\)</span>, where <i>m</i> is the total number of users, and <i>n</i> is the total number of songs. The entry of the matrix for user <i>i</i> at song <i>j</i> represents the relative number of plays that of the song compared to the total number of songs the user listens to, i.e., is the user listens to a song 6 times out of listening to 60 songs total, the relative play would be 0.1. We use relative plays as it will make constructing the similarity matrices easier.</p>
<p>We define the cosine similarity for two arbitrary vectors as:</p>
<div style="text-align: center;">
<p><span class="math">Cosine similarity = \(\frac{u^Tv}{\lVert u \rVert \lVert v \rVert}\) </span></p>
</div>
<p>The user-user similarity matrix can be computed as:</p>
<div style="text-align: center;">
<p><span class="math">User-user similarity = \( RR^T\) </span></p>
</div>
<p>which produces a symmetric <span class = "math">\(m\times m\)</span> matrix, where <span class = "math">\(m\)</span> is the total number of users. The item-item similarity can be calculated in a similar way:</p>
<div style="text-align: center;">
<p><span class="math">Item-item similarity = \( R^TR\) </span></p>
</div>
<p>which produces a symmetric <span class = "math">\(n\times n\)</span> matrix, where <span class = "math">\(n\)</span> is the total number of songs. </p>
<p><br></p>

<h3>Evaluation Metric</h3>
<p>We use the mean average precision (MAP) as the evaluation metric. </p>
<p>For any k, define the <i>precision-at-k</i> <span class = "math">\(P_k\)</span> as the proportion of correct recommendations within the top-<i>k</i> of the predicted ranking:</p>
<div style="text-align: center;">
<p><span class="math">\( P_k(u,y)=\frac{1}{k}\sum_{j=1}^kM_{u,y(j)}\), </span></p>
</div>
<p>next we take the average of the computed precisions:</p>
<div style="text-align: center;">
<p><span class="math">\( AP(u,y)=\frac{1}{n_u}\sum_{k=1}^\tau P_k(u,y)\times M_{u,y_u(k)}\) </span></p>
</div>
<p>where <span class = "math">\(\tau\)</span> is the threshold that represents how many of the top predictions in <span class = "math">\(y_u\)</span> to include and <span class = "math">\(n_u\)</span> is the number of songs in the users hidden history.</p>
<p>Finally, we take the average over all users precisions:</p>
<div style="text-align: center;">
<p><span class="math">\( MAP = \frac{1}{m}\sum_{u}AP(u,y_u)\) </span></p></div>
<p>The R functions for the evaluation metrics are shown below:</p>

<pre class = 'brush: python'>average_precision_at_k <- function(k, actual, predicted){
  score <- 0.0
  cnt <- 0.0
  for (i in 1:min(k,length(predicted)))
  {
    if (predicted[i] %in% actual && !(predicted[i] %in% predicted[0:(i-1)]))
    {
      cnt <- cnt + 1
      score <- score + cnt/i
    }
  }
  score <- score / min(length(actual), k)
  return(score)
}

mAP = mean(average_precision_at_k(500, valid_data, predicted_songs))
</pre>
<p><br></p>
<h3>Strategy - Recommend top 500</h3>
<p>A simple strategy would be to suggest the same top 500 most played songs to all users.</p>
<p>To do this, first, we load in the relevant libraries, and construct the training and validtion datasets. For details on the initial loading of the data from the text files and SQLite databases the R code above.</p>
<pre class="brush: python">library(readr)
library(dplyr)
library(tidyr)
library(Matrix)
library(plyr)
library(pbapply)

# Load in data
triplets <- as.data.frame(read_table('data/kaggle/kaggle_visible_evaluation_triplets.txt'))
colnames(triplets) <- c('User_ID', 'Song_ID', 'Plays')

# Split data into train and validation set
set.seed(666) # reproducibility
train_data <- triplets %>%
  dplyr::group_by(User_ID) %>%
  dplyr::sample_frac(0.8) %>%
  dplyr::ungroup()

valid_data <- setdiff(triplets, train_data)</pre>
<p><br></p>
<p>The top 1000 songs are chosen based on total number number of plays across all users.</p>
<pre class="brush: python"># baseline is to recommend top n most played songs,
top1000songs <- train_data %>%
  dplyr::group_by(Song_ID) %>%
  dplyr::summarise(Total.Plays = sum(Plays)) %>%
  dplyr::arrange(desc(Total.Plays)) %>%
  dplyr::top_n(1000) %>%
  dplyr::ungroup()

getBaseline_AveragePrecision(user){
  actual.songs <- filter(valid_data, User_ID == unique_users$User_ID[user])
  avg.Pres <- average_precision_at_k(k=500, actual = actual.songs$Song_ID,
                                     predicted = top1000songs$Song_ID[1:500])
  return(avg.Pres)
}

mAP_baseline <- pbsapply(seq(nrow(multMat2)), getUser_Average_Precision)
</pre>
<p><br></p>
<h3>Strategy - Recommend songs by finding similar songs to songs in users list of listened songs</h3>
<p>Two songs are similar if they have many users in common that listen to both.</p>
<p>This is achieved in R by creating a sparse matrix, and performing the operations on the sparse matrix.</p>
<pre class="brush: python"><code># Create data frames of the unique songs and users
unique_users <- unique(train_data$User_ID)
unique_songs <- unique(train_data$Song_ID)

unique_users <- as.character(unique_users)
unique_songs <- as.character(unique_songs)

# Create new column where user/song ID -> unique numeric
unique_users <- cbind(unique_users, as.numeric(seq(nrow(as.data.frame(unique_users)))))
unique_songs <- cbind(unique_songs, as.numeric(seq(nrow(as.data.frame(unique_songs)))))

colnames(unique_users) <- c('User_ID', 'UID')
colnames(unique_songs) <- c('Song_ID', 'SID')

train_data$User_ID <- as.character(train_data$User_ID)
train_data$Song_ID <- as.character(train_data$Song_ID)

# Join datasets
train_data_2 <- train_data %>%
  dplyr::left_join(as.data.frame(unique_users), by = 'User_ID') %>%
  dplyr::left_join(as.data.frame(unique_songs), by =  'Song_ID') %>%
  dplyr::group_by(User_ID) %>%
  dplyr::mutate(Relative.Plays = Plays/sum(Plays))

# remove all NAs
train_data_2[is.na(train_data_2)] <- 0

# Create sparse matrix
sparse_rating_df <- sparseMatrix(i = as.numeric(train_data_2$UID),
                                 j = as.numeric(train_data_2$SID),
                                 x = train_data_2$Relative.Plays)</code></pre>
<p><br></p>
<p>The method used to recommend the songs will be to recommend songs that are similar to songs already in the users list of listened songs. This is shown using the Venn diagram below.</p>
<p><br></p>
<center><img src="figs/songSim.png" width="500" align="center"></center>
<p><br></p>
<p>The R code to achieve the item-item similarity is as follows:</p>
<pre class = 'brush: python'><code># Song similarity matrix
multMat1 <- t(sparse_rating_df) %*% (sparse_rating_df)

# Get top 500 similar songs of a given song
gettop500simSong <- function(song){
  user_sim <- multMat1[song,]
  user_sim <- as.data.frame(cbind(user_sim, seq(length(user_sim))))
  colnames(user_sim) <- c('Similarity', 'SID')
  user_sim <- user_sim %>%
    dplyr::left_join(unique_songs, by = 'SID') %>%
    dplyr::arrange(desc(Similarity)) %>%
    dplyr::top_n(500, Similarity)
  return(user_sim)
}

# Get average precision of user via song similarity
getSong_Average_Precision<- function(user){
  # Get the visible song in users song list
  songs <- train_data_2 %>%
    filter(UID == user) %>%
    select(SID)

  # If SID is of factor class change to integer
  if (class(songs$SID) == "factor"){
    songs$SID <- as.integer(levels(songs$SID))[songs$SID]
  }

  # Go through songs and get 500 most similar songs
  top500total <- ldply(songs$SID, gettop500simSong) %>%
    anti_join(songs, by = 'SID') %>% # remove songs already in users song list
    distinct() %>%                   # remove duplicates
    arrange(desc(Similarity)) %>%    # order by similarity
    top_n(500, Similarity)           # take top 500

  # Get actual songs from validation datset
  actual.songs <- filter(valid_data, User_ID == unique_users$User_ID[user])

  # Calculate average precision
  avg.Pres <- average_precision_at_k(k=500, actual = actual.songs$Song_ID, predicted = top500total$Song_ID)
  return(avg.Pres)
}

mAP <- mean(pbsapply(seq(nrow(multMat1)), getSong_Average_Precision))</code></pre>
<p><br></p>
<h3>Strategy - Recommend songs by finding similar users and selecting songs in their list of listened songs </h3>
<p>Two users are similar if they have listened to many of the same songs. The user-user similarity is calculated in a similar way to the item-item similarity. After each users recommendations the songs are ordered in termes of total plays. The Venn diagram of the strategy is shown below.</p>
<p><br></p>
<center><img src="figs/userSim.png" width="500" align="middle"></center>
<p><br></p>
<p>The R code to achieve this is as follows:</p>
<pre class = 'brush: python'><code># User similarity matrix
multMat2 <- sparse_rating_df %*% t(sparse_rating_df)

# Function that recommends songs based on 2 users song list
recommend_by_user <- function(user1, user2){
  # Get song intersection of 2 users
  user1.songs <- train_data %>%
    dplyr::filter(User_ID == user1) %>%
    dplyr::select(Song_ID, Plays)
  user2.songs <- train_data %>%
    dplyr::filter(User_ID == user2) %>%
    dplyr::select(Song_ID, Plays)

  # Get songs in user2, that not in user1
  recommend.songs <- dplyr::anti_join(user2.songs, user1.songs,
                                      by = 'Song_ID') %>%
    dplyr::arrange(desc(Plays)) %>%  # sort by number of plays
    dplyr::select(-Plays)
  return(recommend.songs)
}

getUser_Average_Precision<- function(user){
  # Get top 100 unique users
  user1_sim <- multMat2[user,]
  user1_sim <- as.data.frame(cbind(user1_sim, seq(length(user1_sim))))
  colnames(user1_sim) <- c('Similarity', 'UID')
  user1_sim <- user1_sim %>%
    dplyr::arrange(desc(Similarity)) %>%
    dplyr::top_n(100, Similarity) %>%
    dplyr::left_join(unique_users, by = 'UID')

  # Initialsize empty data frame
  rec.songs <- data.frame()
  i = 1
  while(nrow(rec.songs) < 500){
    # Recommend songs if they have any songs in common (similarity > 0)
    if(user1_sim$Similarity[i] > 0.00000){
      new.songs <- recommend_by_user(user1_sim$User_ID[user], user1_sim$User_ID[i])
      rec.songs <- unique(rbind(rec.songs, new.songs))
    }
    # otherwise choose from top 1000 songs
    else{
      new.songs <- as.data.frame(top1000songs$Song_ID[1:(1000-nrow(rec.songs))+1],
                                 stringsAsFactors = FALSE)
      colnames(new.songs) <- 'Song_ID'
      rec.songs <- unique(rbind(rec.songs, new.songs))
    }
    i = i + 1
  }

  # Get actual songs from validation datset
  actual.songs <- filter(valid_data, User_ID == unique_users$User_ID[user])

  # Calculate averag precision
  avg.Pres <- average_precision_at_k(k=500, actual = actual.songs$Song_ID, predicted = rec.songs$Song_ID)
  return(avg.Pres)
}

mAP <- mean(pbsapply(seq(nrow(multMat2)), getUser_Average_Precision))</code></pre>
<p><br></p>

          					<div class="left">
              					<div class="container">
                					<div class="sideText3">
                  						<span class="line"></span>
                	  					<p></p>
                					</div>
              					</div>

         	 				</div>
      					</div>
    				</div>
				</article>
  				<!-- End Resolution 4 -->

  				<!-- Resolution 5 -->
    			<article id="five" style="background-color:#f7f7f7;">
      				<div class="center">
      					<p><br></p>
          				<h2>Results</h2>
                  <p><br></p>
                  <p>In the results shown, <i>k</i>-fold cross validation is used, for <i>k</i>=5. The MAP for each of the strategies is shown below.</p>
                  <script>
                      var myChart_chordProg = new Chart({...})
                  </script>
                  <canvas id="myChart_chordProg" width="350" height="150"></canvas>
                  <script>
                  var ctx = document.getElementById("myChart_chordProg");
                  ctx.width = 200;
                  ctx.height = 100;
                  var randomColorFactor = function() {
                              return Math.round(Math.random() * 255);
                          };
                  var randomColor = function() {
                              return 'rgba(' + randomColorFactor() + ',' + randomColorFactor() + ',' + randomColorFactor() + ',.7)';
                          };
                  var myChart = new Chart(ctx, {
                      type: 'bar',
                      data: {
                          labels: ['Item/item', 'User/User', 'Baseline'],
                          datasets: [{
                              label: 'MAP',
                              data: [0.0482, 0.0412,0.0213],
                              backgroundColor: 'rgba(24, 188, 156, 0.6)',
                              borderColor: 'rgba(9, 74, 61, 1)',
                              borderWidth: 2
                          }]
                      },
                      options: {
                        title: {
                              display: true,
                              text: 'Mean Average Precision',
                              fontSize: 30
                          },
                          scales: {
                              yAxes: [{
                                  ticks: {
                                      beginAtZero:true
                                  },
                                  scaleLabel: {
                                display: true,
                                labelString: 'MAP at k=500',
                                fontSize: 30
                              }
                              }],
                              xAxes: [{
                                  scaleLabel: {
                                display: true,
                                labelString: 'Strategy',
                                fontSize: 30
                              }
                              }]
                          }
                      }
                  });
                  </script>
                  <p><br></p>
                  <p>We can see that item/item similarity has the largest MAP score, slightly outperforming the user-user similarity strategy. In terms of run time, the base-line strategy is unsurprisingly the quickest, at around 0.72 seconds/user, followed by item-item similarity at around 4.23 seconds per user, and finally the user-user similarity was significantly slower at 121.2 seconds/user. This may be due to the user-user similarity matrix, while smaller than the item-item similarity (110000<sup>2</sup> vs 149029<sup>2</sup>), it is not as sparse, so sorting through the matrix, in looking for common users, as well as allocating memory is more expensive.</p>
                  <p><br></p>


          				<div class="left">


          				</div>
          				<div class="right">
          				</div>
      				</div>
    			</article>
  				<!-- End Resolution 5 -->

				<!-- Resolution 6 -->
    			<article id="six">
      				<div class="center">

<h2>Recommending Songs based on Metadata</h2>
<p><br></p>
<h3>Discovering new artists</h3>
<p>Since item/item similarity was gave the best results and was much quicker to process this is the stratey we will continue with, though the same recommendation methods can be used with the user/user similarity.</p>
<p>Since there are no correct answers, evaluation metrics are redundant, and A/B/n testing would be more appropriate.</p>
<p>To discover new artists we follow a similar method however in the top 500 similar artists we will order in the list in terms of artist ascending familiarity, and suggest those at the top first. The 'artist familiarity' corresponds to how well known in artist is. You can look at familiarity as the likelihood that any person selected at random will have heard of the artist. Kanye West has a familiarity close to 1, while a band like ‘Hot Rod Shopping Cart’ has a familiarity close to zero. In this way songs are both similar to songs in the users lists of listened songs, and unlikely to be heard by the user.</p>
<p>This can be achieved using the R code below.</p>
<pre class = 'brush: python'><code>discoverNewSongs<- function(user){
  # Get users songs
  usersongs <- train_data_2 %>%
    filter(UID == user) %>%
    select(SID)

  # If SID is of factor class change to integer
  if (class(usersongs$SID) == "factor"){
    usersongs$SID <- as.integer(levels(usersongs$SID))[usersongs$SID]
  }

  # Get top 500 similar songs for each song in user song list
  top500total <- ldply(usersongs$SID, gettop500simSong) %>%
    dplyr::anti_join(usersongs, by = 'SID') %>%                 # remove songs already in song list
    dplyr::distinct() %>%                                       # remove duplicates
    dplyr::top_n(500, Similarity) %>%                           # take top 500 based on similarity
    dplyr::left_join(songs, by = c('Song_ID' = 'song_id')) %>%  # join with metadata dataset
    dplyr::arrange(artist_familiarity) %>%                      # sort based on artist familiarity
    dplyr::select(artist_name, title, artist_familiarity, Song_ID)
  return(top500total)
}</code></pre>
<p><br></p>
<h4>Playlists to chillout/workout to</h4>
<p>Many songs from chillout playlists, such as those found on Spotify or last.fm have slow and easy-going, characterized by a low tempo that will relax the listener. Alternatively, if listeners want to get motivated to workout they may want listen to songs with high tempo that will get their heartrate up. This can be done with the following code:</p>
<pre class = 'brush: python'><code># Find songs with low tempo
downbeatSongs<- function(user){
  # Get users songs
  usersongs <- train_data_2 %>%
    filter(UID == user) %>%
    select(SID)

  # If SID is of factor class change to integer
  if (class(usersongs$SID) == "factor"){
    usersongs$SID <- as.integer(levels(usersongs$SID))[usersongs$SID]
  }

  # Get top 500 similar songs for each song in user song list
  top500total <- ldply(usersongs$SID, gettop500simSong) %>%
    dplyr::distinct() %>%                                 # Remove duplicates
    dplyr::top_n(500, Similarity) %>%                     # get 500 most popular songs
    dplyr::left_join(song2track, by = 'Song_ID') %>%      # to convert song_id to trackid
    dplyr::left_join(song_metadata, by = c('Track_ID' = 'track_id')) %>% # join with metadata
    dplyr::arrange(tempo) %>%                             # order with respect to tempo
    dplyr::select(Song_ID, tempo) %>%                     # select releveant columns
    dplyr::filter(!is.na(Song_ID))                        # remove NAs
  return(top500total)
}

# Find songs with high tempo
upbeatSongs<- function(user){
  usersongs <- train_data_2 %>%
    filter(UID == user) %>%
    select(SID)

  # If SID is of factor class change to integer
  if (class(usersongs$SID) == "factor"){
    usersongs$SID <- as.integer(levels(usersongs$SID))[usersongs$SID]
  }

  # Get top 500 similar songs for each song in user song list
  top500total <- ldply(usersongs$SID, gettop500simSong) %>%
    dplyr::distinct() %>%                                 # Remove duplicates
    dplyr::top_n(500, Similarity) %>%                     # get 500 most popular songs
    dplyr::left_join(song2track, by = 'Song_ID') %>%      # to convert song_id to trackid,
    dplyr::left_join(song_metadata, by = c('Track_ID' = 'track_id')) %>% # join with metadata
    dplyr::arrange(desc(tempo)) %>%                       # order with respect to tempo
    dplyr::select(Song_ID, tempo) %>%                     # select releveant columns
    dplyr::filter(!is.na(Song_ID))                        # remove NAs
  return(top500total)
}</code></pre>
<p><br></p>
<p>In this application it doesn't matter if the songs are already in the users list of listened songs, unlike for recommending new music.</p>
<p>This serves as a good template for A/B/n testing, creating indices based on a variety of metadata may also be used, for example a workout index may be defined as the <span class = 'math'>\(WI = \log(tempo\times danceability)\)</span>, where the danceabilty is defined from the <a target='_blank' href="https://developer.spotify.com/spotify-echo-nest-api/">Spotify/echonest API</a>. A/B testing can by varying the indices created, selecting songs based on the indices. The best index can be determined based on user feedback, such as number of plays, shares, or follows of the playlist. </p>
<p><br></p>

<p><br></p>


          				<div class="left">
            				<p></p>
            				<div class="container">
               					<div class="sideText5">
                  					<span class="line"></span>
                	 				<p></p>
                				</div>
            				</div>
      						<p></p>
        				</div>
          				<div class="right">
        				</div>
       				</div>
    			</article>
    			<!-- End Resolution 6 -->

				<!-- Resolution 7 -->
    			<article id="seven" style="/*background-color:#f7f7f7;*/ padding-bottom: 0;">
					<div class="center">
					   <div style="clear:both;"></div>
      				</div>
    			</article>
  				<!-- End Resolution 7 -->

				<!-- Resolution 8 -->
    			<article id="eight">
      				<div class="center">
              			<h2>Conclusion</h2>
                    <p>Overall, a successful recommendation system is made and has been applied to create custom mood-based playlists ready for A/B/n testing. It is shown that recommendation system based on item-item gives the largest mean average precision for the dataset. All strategies can be combined with different weights, however this in unrealistic with a single machine. Other methods to recommend songs is to find the user-user and item-item similarity via singular value decomposition, as this is fast and efficient, yet has a tendency to overfit, without regularization.</p>
<p><br></p>
              			<div class="left">
                			<div class="container">
                				<div class="sideText4">
                  					<span class="line"></span>
                		  			<p></p>
                				</div>
              				</div>
      						<p></p>
            			</div>
              			<div class="right">
              			</div>
              			<div style="clear: both;"></div>
                     </div>
              		 <div class="center">
              		</div>
    			</article>
  				<!-- End Resolution 8 -->

    			<!-- Resolution 9-->
    			<article id="forecast" style=" display: block; margin-bottom: 0px; ">
      					<div class="center">

              				<p><br></p>
                      <h2>Related Projects</h2>
                      <p><br></p>
                      <div id="twoimages" style = "display:inline-block;">
                      <div class="post-overlay-header" style="background-image: url(/img/playlist.png);background-position: center; background-size: 600px ;">
                                <div class="post-overlay-header-title">
                                  <h1 class="post-title">
                                    <a href="/blog/Ultimate-Playlist-Title/">
                                      The Ulimate Playlist Title
                                    </a>
                                  </h1>
                                </div>
                              </div>

                              <div class="post-overlay-header" style="background-image: url(/img/two-listeners.jpg); background-position: center; background-size: 600px ;">
                                <div class="post-overlay-header-title">
                                  <h1 class="post-title">
                                    <a href="/blog/Two-Listeners/">
                                      Two Types of Music Streamer
                                    </a>
                                  </h1>
                                </div>
                              </div>

                      </div>
              				<p><br></p>
              				<p><br></p>
              				<p><br></p>
              				<p><br></p>
              				<p><br></p>
              				<p class style="font-style: italic; margin-bottom: 33px;">
      					</div>

    			</article>
    			<!-- End Resolution 9 -->

        	</div> <!--extra wrapper-->
         	<footer class="text-center">
        <div class="footer-below">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <h4>Matthew Moocarme - moocarme@gmail.com</h4>
                    </div>
                </div>
            </div>
        </div>
    </footer>
    	</div><!-- end wrapper -->
 	<script type="text/javascript" src="//munchkin.marketo.net//munchkin-beta.js"></script><script>Munchkin.init('062-HAC-076', {customName: 'past-forward-2016', wsInfo: 'j1RR'});</script>
 	</body>


<style>
#mktoForm_375 {
    width: auto!important;
}
</style>
<script type="text/javascript">
     SyntaxHighlighter.all()
</script>
<script>
$(document).ready(function() {



	var sections = $('article'),
        nav = $('nav'),
        nav_height = nav.outerHeight();

	$(window).on('scroll', function () {

  		var cur_pos = $(this).scrollTop();

  		sections.each(function() {
    	var top = $(this).offset().top - nav_height,
        bottom = top + $(this).outerHeight();

    	if (cur_pos >= top && cur_pos <= bottom) {
      		nav.find('a').removeClass('active');
      		sections.removeClass('active');

      		$(this).addClass('active');
      		nav.find('a[href="/examples/SmoothPageScroll/#'+$(this).attr('id')+'"]').addClass('active');
    	}
  		});

      	if ($('#one .left').isOnScreen()) {
    		var wScroll = $(this).scrollTop();
          	var $sideText1 = $('.sideText1');
            var containerScroll = wScroll - $sideText1.parent().offset().top + 1000;
      		$sideText1.css({
       			'transform' : 'translate(0px, +'+ containerScroll/10 +'%)'
      		});
      	}

      	if ($('#two .left').isOnScreen()) {
    		var wScroll = $(this).scrollTop();
          	var $sideText2 = $('.sideText2');
          	var containerScroll2 = wScroll - $sideText2.parent().offset().top + 1000;
      		$sideText2.css({
       			'transform' : 'translate(0px, +'+ containerScroll2/10 +'%)'
      		});
      	}

      	 if ($('#four .left').isOnScreen()) {
    		var wScroll = $(this).scrollTop();
          	var $sideText3 = $('.sideText3');
          	var containerScroll3 = wScroll - $sideText3.parent().offset().top + 1000;
      		$sideText3.css({
       			'transform' : 'translate(0px, +'+ containerScroll3/10 +'%)'
      		});
      	}

      	if ($('#eight .left').isOnScreen()) {
    		var wScroll = $(this).scrollTop();
          	var $sideText4 = $('.sideText4');
          	var containerScroll4 = wScroll - $sideText4.parent().offset().top + 1000;
      		$sideText4.css({
       			'transform' : 'translate(0px, +'+ containerScroll4/10 +'%)'
      		});
      	}

      	if ($('#six .left').isOnScreen()) {
    		var wScroll = $(this).scrollTop();
          	var $sideText5 = $('.sideText5');
          	var containerScroll5 = wScroll - $sideText5.parent().offset().top + 1000;
      		$sideText5.css({
       			'transform' : 'translate(0px, +'+ containerScroll5/10 +'%)'
      		});
      	}

      	/** Measures the height of hero then nav bar appears after it **/
      	var heroHeight = $('.hero').height();

      	if ($(this).scrollTop() > heroHeight) {
          $('.nav-toggle').addClass('show');
        } else {
           $('.nav-toggle').removeClass('show');
        }

      	/** For Desktop Nav only (from 1170px wide) **/
      	if ($(this).scrollTop() > heroHeight){
    		$('#desktopNav').addClass('fixedElement');
  		} else {
    		$('#desktopNav').removeClass('fixedElement');
  		}
	});

  	/**** Smooth Scrolling ****/
	$('a[href*=#]:not([href=#])').click(function() {
    	if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'')
        	|| location.hostname == this.hostname) {

        	var target = $(this.hash);
        	target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
           	if (target.length) {
            	$('html,body').animate({
                	scrollTop: target.offset().top
            	}, 1000);
            	return false;
        	}
    	}
	});


});


  /*** Navigation menu toggle ***/
  $('.nav-toggle').on('click', function(){
    $('.wrapper').toggleClass('open');
    $('.main-navigation-left').toggleClass('open');
    $('.nav-toggle').toggleClass('open');
  });

  /*Desktop Fixed Nav*/
  var stickyTop = $('#desktopNav').offset().top;


  /** Function to see when a div is in view **/
  $.fn.isOnScreen = function(){
    var win = $(window);
    var viewport = {
        top : win.scrollTop(),
        left : win.scrollLeft()
    };

    viewport.right = viewport.left + win.width();
    viewport.bottom = viewport.top + win.height();

    var bounds = this.offset();
    bounds.right = bounds.left + this.outerWidth();
    bounds.bottom = bounds.top + this.outerHeight();

    return (!(viewport.right < bounds.left || viewport.left > bounds.right || viewport.bottom < bounds.top || viewport.top > bounds.bottom));
  };
</script></html>
